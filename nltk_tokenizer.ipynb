{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "def custom_sentence_tokenizer(text, tokenizer, testing = False, verbose = False):\n",
    "    \"\"\"\n",
    "    Description: Splits a piece of text, should be an entire note, into sentences. Relies on \n",
    "        the NLTK sentence tokenizer, and then runs checks on each split sentence. If a sentence\n",
    "        is found to be over 400 tokens, it's assumed to be a list of clinical terms, in which case\n",
    "        split_medical_list() is run on this text. If this doesn't work, then it's assumed to be a\n",
    "        paragraph of text with headers and no significant new lines. This is then split using a\n",
    "        regular expression.\n",
    "        Note that this does not accurately split text up into sentences, and tends to create \n",
    "        longer 'sentences', but these 'sentences' usually stop at what can be considered proper\n",
    "        sentence boundaries. So we aim for longer 'sentences' over shorter spans of text which\n",
    "        run the risk of splitting up proper sentences.\n",
    "    Usage:\n",
    "                my_text = re.sub(\"â€|™|˜\", \"\", my_text)\n",
    "                # I think these are single quote characters that got messed up.\n",
    "                my_text = re.sub(\"\\xa0+\", \" \", my_text)\n",
    "                # These take up a lot of space in the text and messup the tokenizer\n",
    "                my_text = re.sub(\"\\r\\n\", \"\\n\", my_text)\n",
    "                # replacing Windows new line with just new line\n",
    "                text = re.sub('\\\\\\\\.br\\\\\\\\', \"\\n\", text)\n",
    "                # I think this are weird html leftovers\n",
    "                sentences = custom_sentence_tokenizer(text = my_text, tokenizer = bert_tokenizer)\n",
    "\n",
    "    Input:\n",
    "        text (str): A string of text from a clinical note. No processing is performed in this\n",
    "            function so all pre-processing needs to happen before sentence tokenization.\n",
    "            See usage above for suggestions.\n",
    "        tokenizer (BERT Tokenizer): Can be any tokenizer, but should be BERT tokenizer. Used to\n",
    "            determine if there are too many tokens in a sentence.\n",
    "                from transformers.tokenization_bert import BertTokenizer\n",
    "                tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
    "        testing (boolean): If True then extra information is returned. See below.\n",
    "        verbose (boolean): Just prints more about what's going on\n",
    "    Output:\n",
    "        sentences_final (list(str)): A list of sentences.\n",
    "        sents_not_split (int): optionally returned if testing is True. This is the number of\n",
    "            sentences which could not be split.\n",
    "    TODO\n",
    "        1) This wil return single sentences if nltk looks at a text and only extracts one sentence\n",
    "            out that is under the max_sentence_toks. Can happen if the whole input is a list.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    sentences_custom_tokenized = []\n",
    "    max_sentence_toks = 100# max number of tokens in a sentence otherwise we assume it's a list.\n",
    "    sents_not_split = 0\n",
    "    for sentence in sentences:\n",
    "        toks = tokenizer.tokenize(sentence)\n",
    "        if len(toks) >= max_sentence_toks or len(sentences) == 1:\n",
    "            \n",
    "            sub_sentences = [sentence]\n",
    "            if '·' in sentence:\n",
    "                if verbose:\n",
    "                    print(\"Splitting a medical list\\n\\n[\")\n",
    "                    print(sentence)\n",
    "                    print(\"]\\n\\n\")\n",
    "\n",
    "                    sub_sentences = split_medical_list(sentence)\n",
    "\n",
    "            \n",
    "            if len(sub_sentences) == 1:\n",
    "                # This code assumes that if we're here we hit a sentence\n",
    "                # which isn't a list, but a large paragraph of headers\n",
    "                # with no new lines that separate them. \n",
    "                # the regex below looks for single or multi word headers\n",
    "                # all capitalized that ends with a colon.\n",
    "                # and it assumes that the sentence could not be split at all\n",
    "                if verbose:\n",
    "                    print(\"could not split the string\\n\\n[\" + sentence + \"]\\n\\n\")\n",
    "                    print(\"Assuming this text is is a large paragraph and splitting\")\n",
    "                    print(\"LET'S KICK IT INTO OVERDRIVE\")\n",
    "                # splitting by headers in a string.\n",
    "                sub_sentences = re.split(r'([A-Z0-9][A-Z0-9. ]*:)', sentence)\n",
    "                \n",
    "            sentences_custom_tokenized.extend(sub_sentences)\n",
    "            if len(sub_sentences) == 1:\n",
    "                sents_not_split += 1\n",
    "            if verbose:\n",
    "                print(\"original length: {}\".format(len(toks)))\n",
    "                for split_sent in sub_sentences:\n",
    "                    print(\"\\t{}\".format(len(tokenizer.tokenize(split_sent))))\n",
    "        else:\n",
    "            sentences_custom_tokenized.append(sentence)\n",
    "    assert len(sentences_custom_tokenized) >= len(sentences)\n",
    "    sentences_final = []\n",
    "    for elem in sentences_custom_tokenized:\n",
    "        if elem.strip() != \"\":# removing empty tokens.\n",
    "            sentences_final.append(elem)\n",
    "    if testing:\n",
    "        return(sentences_final, sents_not_split)\n",
    "    else:\n",
    "        return(sentences_final)\n",
    "\n",
    "\n",
    "def split_medical_list(text):\n",
    "    \"\"\"\n",
    "    Description: Splits a piece of text up using some heuristics for columbia data.\n",
    "        The text is split based on new lines. Then some lines are combined if they are not\n",
    "        the beginnings of a new list. A list often starts with \" \" or \"·\", but if a line is\n",
    "        empty of has an alphanumeric character in the first character then it is the start\n",
    "        of a new list element, and thus its on sentence.\n",
    "    Input:\n",
    "        text (str): A string which is the result of using nltk on a larger chunk of text, and\n",
    "            finding that this particular input could not be parsed down to a good length.\n",
    "    Output:\n",
    "        sentences_fix_split_list_item (list(str)): A list of sentences.\n",
    "    TODO:\n",
    "        1)\n",
    "    \"\"\"\n",
    "    sentences_new_line_split = text.split(\"\\n\")\n",
    "    sentences_fix_split_list_item = []\n",
    "    curr_sentence = \"\"\n",
    "    for idx, elem in enumerate(sentences_new_line_split):\n",
    "        if idx == 0:\n",
    "            curr_sentence = elem\n",
    "        elif elem == \"\" or begins_list_element(my_text = elem):\n",
    "            # above checks if we've reached end or are about to start a new element in the list.\n",
    "            if curr_sentence.strip() != \"\":# don't append empty lines.\n",
    "                sentences_fix_split_list_item.append(curr_sentence)\n",
    "            curr_sentence = elem\n",
    "        else:# guessing that this line should be joined with the previous line\n",
    "            if curr_sentence == \"\":\n",
    "                curr_sentence = elem\n",
    "            else:\n",
    "                curr_sentence += \" \" + elem\n",
    "    if curr_sentence.strip() != \"\":\n",
    "        sentences_fix_split_list_item.append(curr_sentence)\n",
    "\n",
    "\n",
    "    # check to make sure all original lines made it into the data\n",
    "    for line in sentences_new_line_split:# This will slow down the tokenizer, but is a good idea\n",
    "        # to make sure we're not losing any information.\n",
    "        text_found = False\n",
    "        if line.strip() != \"\":\n",
    "            for fixed_line in sentences_fix_split_list_item:\n",
    "                if line in fixed_line:\n",
    "                    text_found = True\n",
    "                    break\n",
    "            assert text_found, \"missing original string: {}\".format(line)\n",
    "    return(sentences_fix_split_list_item)\n",
    "\n",
    "\n",
    "\n",
    "def begins_list_element(my_text):\n",
    "    \"\"\"\n",
    "    Description: Returns true when an piece of text is the beginning of a new list elemnt\n",
    "        usually starting with \" \" or \"·\". This is CUIMC specific.\n",
    "    Input:\n",
    "        my_text (str): Piece of text from splitting on new line.\n",
    "    Output: Boolean whether or not my_text is the beginning of a list element.\n",
    "    TODO:\n",
    "    \"\"\"\n",
    "    if my_text.startswith(\"·\"): # or my_text.startswith(\" \"):\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not split the string\n",
      "\n",
      "[In the CMED CCU he became hypotensive to SBP 80 s.\n",
      "Labetalol was stopped and he received a 500 cc fluid bolus and his blood pressure rose to SBP 90 s.\n",
      "Cardiac and infectious sources of hypotension were considered , but cardiac enzymes were not changed from prior studies and he had no localizing signs of infection ; blood cultures were sent and a ultrasound of the L arm AVF ordered to rule out abscess at the site .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 101\n",
      "\t101\n",
      "Splitting a medical list\n",
      "\n",
      "[\n",
      "·  kept euvolemic and monitored for signs of overload\n",
      "·  Low Na diet with 1 liter fluid restriction\n",
      "·  may need to diurese based on clinical status , swan numbers\n",
      "· Rhythm : No ectopy post cath MI\n",
      "· DM : on metformin at home , will hold given cath / dye adn cover with SSI\n",
      "· Cocaine use : last use this morning , no BB given this ; considered using CCB / phentolamine if chest pain recurs .\n",
      "]\n",
      "\n",
      "\n",
      "original length: 100\n",
      "\t13\n",
      "\t9\n",
      "\t14\n",
      "\t11\n",
      "\t24\n",
      "\t29\n",
      "could not split the string\n",
      "\n",
      "[MEDQUIST36\n",
      "D : 2017-03-08 10:57\n",
      "T : 2017-03-10 07:01\n",
      "JOB # : 53408\n",
      "( cclist )\n",
      "***************************\n",
      "Please note that all of the conversations regarding code status took place during we icu admit ; and that this patient passed away in early am hours of night she was called back out to the medicine floor , therefore she had not yet been re-evaluated by the floor medicine attending , but had been earlier that day by the icu attending .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 127\n",
      "\t3\n",
      "\t2\n",
      "\t4\n",
      "\t3\n",
      "\t1\n",
      "\t2\n",
      "\t4\n",
      "\t3\n",
      "\t105\n",
      "could not split the string\n",
      "\n",
      "[The patient had an echocardiogram on day two of admission , which revealed a mildly dilated left atrium , mild symmetric LVH , normal LV cavity size , mild region LV systolic dysfunction , arresting regional wall motion abnormality including focal apical hypokinesis , a normal right ventricular chamber size and free wall motion , a moderately dilated aortic root , a mildly dilated ascending aorta , normal aortic valve leaflet , normal mitral valve leaflet and no pericardial effusions .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 112\n",
      "\t112\n",
      "could not split the string\n",
      "\n",
      "[The patient was transferred to Fairm of Ijordcompmac Hospital and had 4-7 mm ST segment elevations across the precordium with Q and apos;s in V1 and V2 , 2 mm ST elevation in AVL , and 1-2 mm reciprocal ST depression in II , III , and F.\n",
      "On physical examination at that time he had bright red blood per rectum and therefore lysis was deferred and he was taken directly to the cardiac catheterization lab .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 102\n",
      "\t102\n",
      "could not split the string\n",
      "\n",
      "[HISTORY OF PRESENT ILLNESS :\n",
      "Miss Siehjesc is an 85-year-old woman with a past medical history significant for Parkinson 's Disease of ten years duration , supraventricular tachycardia , and a history of colon carcinoma , who was in her usual state of health until 11:30 on the morning of admission when she felt the acute on set of 5 out of 10 right sided chest pain with radiation to her sternum but not to her neck or arms or back .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 103\n",
      "\t0\n",
      "\t5\n",
      "\t58\n",
      "\t2\n",
      "\t38\n",
      "could not split the string\n",
      "\n",
      "[Brief Hospital Course :\n",
      "BRIEF OVERVIEW :\n",
      "57 yo F with h/o polyglandular autoimmune syndrome initially admitted in May to FICU for suicide overdose then transferred to Whittier Rehab Hospital 4 for depression , who was transferred to the medical floor for a syncopal episode and hypotension to 60 systolic that returned to baseline with 2.5L IVF who was subsequently transferred to the CMED CSRU for a recurrent episode of hypotension , fevers and concern for sepsis .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 110\n",
      "\t4\n",
      "\t3\n",
      "\t103\n",
      "could not split the string\n",
      "\n",
      "[HISTORY OF PRESENT ILLNESS : \n",
      "Ms. Lenkpruskihkooglekih is a 63-year-old lady with a history of frequent premature ventricular contractions and infrequent short runs of non-sustained ventricular tachycardia ( one four-beat run ) in 1991 , for which several antiarrhythmic agents including Propranolol , Quinidine , Procainamide , Tenormin , Norpace , Corgard , and Flecainide were used , but were stopped because of intolerance .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 117\n",
      "\t0\n",
      "\t5\n",
      "\t112\n",
      "Splitting a medical list\n",
      "\n",
      "[\n",
      "·  B-blocker IV , Dilt PRN for PAF\n",
      "·  Hold coumadin for afib given hx of upper GIB and surgery in AM\n",
      "·  Continue ASA , plavix\n",
      "·  ROMI , check AM ECG\n",
      "· COPD / Restrictive lung disease :\n",
      "·  Nebs / MDI PRN\n",
      "·  no need for steroids now\n",
      "·  expect prolonged wean given previous history of prolonged wean s/p colonic resection\n",
      "·  incentive spirometry for atelectasis\n",
      "· Hip fracture :\n",
      "·  pain control with diluadid , tylenol\n",
      "·  lovenox tonight x1 , hold AM dose per CMED CCU\n",
      "·  Pt to OR in early AM\n",
      "· Anemia :\n",
      "·  iron studies\n",
      "·  TSH\n",
      "· no need for transfusion currently , keep Hct > 30\n",
      "· Hypokalemia :\n",
      "·  60IV K now\n",
      "·  continue PO K\n",
      "·  check lytes in PM\n",
      "· Cellulitis :\n",
      "·  continue unasyn\n",
      "·  hold off on X-rays for now\n",
      "· DM :\n",
      "·  RISS - tight glucose control pre-op\n",
      "· PPx :\n",
      "·  Protonix , Lovenox , R boot as per CMED CCU\n",
      "· Diet :\n",
      "NPO\n",
      "· Code :\n",
      "Full --> DNR / DNI\n",
      "CMED course :\n",
      "ORIF with repair of neck fracture 2016-03-23 .\n",
      "]\n",
      "\n",
      "\n",
      "original length: 272\n",
      "\t14\n",
      "\t19\n",
      "\t7\n",
      "\t8\n",
      "\t8\n",
      "\t8\n",
      "\t7\n",
      "\t19\n",
      "\t10\n",
      "\t4\n",
      "\t12\n",
      "\t16\n",
      "\t7\n",
      "\t4\n",
      "\t3\n",
      "\t3\n",
      "\t13\n",
      "\t7\n",
      "\t5\n",
      "\t4\n",
      "\t7\n",
      "\t5\n",
      "\t5\n",
      "\t9\n",
      "\t4\n",
      "\t10\n",
      "\t4\n",
      "\t16\n",
      "\t5\n",
      "\t29\n",
      "could not split the string\n",
      "\n",
      "[Service :\n",
      "CMI ; then to Medcine ; then transferred to CCU\n",
      "HISTORY OF PRESENT ILLNESS :\n",
      "The patient is an 83-year-old male with a history of diabetes mellitus , steroid-treated polymyalgia rheumatica , hypertension , benign prostatic hypertrophy , and high cholesterol who presented for a lower extremity peripheral angiography for bilateral foot ulcers , and he was found to an evaluated blood urea nitrogen , and creatinine , and potassium .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 106\n",
      "\t15\n",
      "\t5\n",
      "\t86\n",
      "could not split the string\n",
      "\n",
      "[Service :\n",
      "CCU\n",
      "HISTORY OF PRESENT ILLNESS :\n",
      "The patient is a 47 - year-old male with a past medical history of coronary artery disease , status post 2-vessel percutaneous transluminal coronary angioplasty in 2005 , 3-vessel percutaneous transluminal coronary angioplasty in 2009 , hypertension , new onset type 2 diabetes , and hypercholesterolemia who presents with the sudden onset of substernal chest pain status post exercise .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 101\n",
      "\t4\n",
      "\t5\n",
      "\t92\n",
      "could not split the string\n",
      "\n",
      "[Service :\n",
      "MEDICINE\n",
      "History of Present Illness :\n",
      "Mr. Lockley is a 73 yo male with a complicated past medical history , recently discharged from St. Margaret 's Center for Women Infants on 08-02 following a prolonged admission for STEMI , respiratory failure felt secondary to pulmonary edema requiring intubation and subsequent tracheostomy 02-22 failure to wean , sepsis and C.difficile colitis treated with Vancomycin and Flagyl with a course of Levophed .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 102\n",
      "\t102\n",
      "********************************************************************************\n",
      "Splitting a medical list\n",
      "\n",
      "[\n",
      "·  transfuse 2 units today , with lasix\n",
      "· GERD - PPI\n",
      "· DM - glipizide , ISS\n",
      "· PMR - cont prednisone\n",
      "· GI : Ms. Pimental is an unfortunate 95 year old woman , status post a recent fall necessitating right ORIF of the hip and right wrist fracture ORIF , who was in the hospital for this event , when it was noted that she had abdominal pain , distention and coffee ground emesis with worsening mental status and renal failure .\n",
      "]\n",
      "\n",
      "\n",
      "original length: 109\n",
      "\t11\n",
      "\t6\n",
      "\t10\n",
      "\t10\n",
      "\t72\n",
      "could not split the string\n",
      "\n",
      "[04-27 results from Blood Cx from W+I :\n",
      "04-24 PICC Bld Cx : pseudomonas Diaz to zosyn , cipro , cefepime , Tardugno -- staph epi- Gray to vanc\n",
      "04-24 Peripheral Bld Cx : pseudomonas as above\n",
      "04-24 Urine Cx : pseudomonas as above\n",
      "Abx changed to vanc , zosyn , cipro , fluc , azith .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 101\n",
      "\t11\n",
      "\t2\n",
      "\t88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not split the string\n",
      "\n",
      "[Brief Hospital Course :\n",
      "A/P :\n",
      "82 y/o f w h/o afib , SSS s/p pacer 05-08 c/b PTX requiring CT , CAD , who was readmitted 05-24 with ARF and lethargy , found to have a large pericardial effusion and bilateral pleural effusions , with echo showing no evidence of tamponade , who is transferred for possible pericardial effusion drainage and treatment of CHF , as well as drainage of bilateral pleural effusions .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 117\n",
      "\t6\n",
      "\t2\n",
      "\t109\n",
      "could not split the string\n",
      "\n",
      "[Service :\n",
      "MEDICINE\n",
      "History of Present Illness :\n",
      "47 yo F w/ h/o steroid-induced hyperglycemia , SLE w/ h/o pericarditis , transverse myelitis w/ paraplegia and neurogenic bladder s/p urostomy w/ ileal conduit , h/o ureteropelvic stone and urosepsis , and h/o RLE DVT a/w F 2014-11-29 transferred to CMED 2014-11-30 for hypotn resistant to IVFs and stress steroids .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 120\n",
      "\t120\n",
      "could not split the string\n",
      "\n",
      "[Brief Hospital Course :\n",
      "47 yo F w/ h/o steroid-induced hyperglycemia , SLE w/ h/o pericarditis , transverse myelitis w/ paraplegia and neurogenic bladder s/p urostomy w/ ileal conduit , h/o ureteropelvic stone and urosepsis , and h/o RLE DVT admitted 11-29 w/ left pyelo and right 8 mm proximal ureteral stone w/ right hydro s/p perc urostomy tube to relieve right hydro .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 123\n",
      "\t123\n",
      "could not split the string\n",
      "\n",
      "[HISTORY OF PRESENT ILLNESS :\n",
      "The patient is a 65-year-old man with refractory CLL , status post non-myeloblative stem cell transplant approximately nine months prior to admission , and status post prolonged recent Retelk County Medical Center stay for Acanthamoeba infection of skin and sinuses , complicated by ARS due to medication toxicity , as well as GVHD and recent CMV infection , readmitted for new fever , increasing creatinine , hepatomegaly and fluid surge spacing , in the setting of hyponatremia .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 119\n",
      "\t0\n",
      "\t5\n",
      "\t114\n",
      "could not split the string\n",
      "\n",
      "[Clinical progression of skin and sinus infection on maximal antimicrobial therapy continued , with emergence on November 20 of a new right-sided ptosis in association with a left homonymous hemianopsia , and fleeting confusion while febrile , prompting head MRI which revealed a large 5 x 2 x 4.3 cm region in the right occipital lobe of hemorrhage and edema , with dural and , likely , leptomeningeal enhancement in association with small foci in the right cerebellum and pons , concerning for early lesions of similar type .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 123\n",
      "\t123\n",
      "could not split the string\n",
      "\n",
      "[Service :\n",
      "CMED\n",
      "History of Present Illness :\n",
      "Patient is a 75 year old right handed male with past medical history of coronary artery disease s/p NQWMI 02-25 , s/p LAD angioplasty and stent 05-26 , dementia , hyperlipidemia , aortic stenosis , atrial fibrillation on coumadin who presented from his CMED CSRU doctor 's office wtih acute onset left sided weakness and dysarthria .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 102\n",
      "\t102\n",
      "could not split the string\n",
      "\n",
      "[Lab values :\n",
      "Sodium 139 ; potassium 4.1 ; BUN 15 ; creatinine 1.1 ; magnesium 1.6 ; SGPT 19 ; SGOT 20 ; alkaline phosphatase 66 ; total bilirubin 0.6 ; direct bilirubin 0.2 ; total cholesterol 234 ; triglycerides 274 ; HDL 44 ; LDL 135 ; hemoglobin A1c 6.7 ; white cell count 6.1 ; hematocrit 36.4 ; platelet count 201 .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 112\n",
      "\t112\n",
      "could not split the string\n",
      "\n",
      "[An echocardiogram was obtained on 4-26 which showed concentric left ventricular hypertrophy with normal _____ left ventricular function , severe right ventricular dilatation with septal hypokinesis and flattening with a question of right ventricular apical clot raised with mild aortic stenosis , severe tricuspid regurgitation and increased pulmonary artery pressure of approximately 70 millimeters , consistent with fairly severe pulmonary hypertension .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 101\n",
      "\t101\n",
      "could not split the string\n",
      "\n",
      "[The patient  and apos;s incisions sternal and right leg were clean and healing well , normal sinus rhythm at 70-80 , with blood pressure 98-110/60 and patient was doing well , recovering , ambulating , tolerating regular diet and last hematocrit prior to discharge was 39% with a BUN and creatinine of 15 and 1.0 , prothrombin time level of 13.8 , chest X-ray prior to discharge showed small bilateral effusions with mild cardiomegaly and subsegmental atelectasis bibasilar and electrocardiogram showed normal sinus rhythm with left atrial enlargement and no acute ischemic changes on electrocardiogram .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 155\n",
      "\t155\n",
      "could not split the string\n",
      "\n",
      "[He will be discharged to rehab on a regimen of Coumadin 5 mg po today then daily for an INR goal of 2-3 , Ofloxacin 400 mg po bid to be discontinued on 11/05/96 , Dexedrine 5 mg po qd , Omeprazole 20mg po qd , Erythromycin eye ointment OU bid , Heparin at its present rate adjusting per partial thromboplastin time bid , and discontinuing when the Coumadin is therapeutic , Tylenol 650 mg po q4 prn , Colace 100 mg po bid .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 129\n",
      "\t129\n",
      "Splitting a medical list\n",
      "\n",
      "[\n",
      "Admission Status :\n",
      "ED :\n",
      "REc and apos;d duonebs , solumedrol 125\n",
      "Vitals :\n",
      "t97.5 , hr 117 , bp156/81 , rr28 , o2 sats 87% RA ; 95% 4L\n",
      "Exam :\n",
      "NAD , pleasant , speaking in complete sentences , poor air movement bilaterally , L  and gt; R , no wheezes or rales , rrr , distant , abd benign , no edema , alert and oriented times three , no focal deficits , conversant Studies :\n",
      "·  EKG sinus 92 , no ST changes\n",
      "·  CXR no focal consolidation or edema , old biapical scarring ABG 7.34/79/74 U / A negative\n",
      "Daily Status :\n",
      "improving , but still poor air movement , diffusely wheezy on exam , at baseline 2L o2 requirement\n",
      "A / P :\n",
      "75 y / o F with h / o COPD c / b frequent exacerbations p / w typical flare symptoms .\n",
      "]\n",
      "\n",
      "\n",
      "original length: 208\n",
      "\t112\n",
      "\t10\n",
      "\t86\n",
      "could not split the string\n",
      "\n",
      "[Problem List :\n",
      "CV - Ischemia ASA , lisinopril Pump no evidence of failure\n",
      "Rhythm Resp - COPD\n",
      "flare - steroids , cont prednisone 60 , taper slowly as tolerated , duonebs , advair , singulair , spiriva , claritin azithromycin for atypical bronchitis to complete a 5 day course , keep o2 sat 90-94 , home nocturnal CPAP not tolerated in house , does well on nc , appears ato be at baseline\n",
      "Renal -\n",
      "Cr 0.8 , stress incontinence by symptoms with increased cough , no evidence of uti , cont to closely monitor\n",
      "GI - Bowel regimen\n",
      "Heme - Chronic Fe deficiency anemia , cont iron\n",
      "Endo - DM on insulin with steroids\n",
      "ID - afebrile , no wbc , started on Azithromycin for COPD flare\n",
      "FEN - ADA diet\n",
      "PPx - Lovenox , PPI\n",
      "Dispo - to rehab when resp status improved , PT consulted\n",
      "Code - FC\n",
      "ADDITIONAL COMMENTS :\n",
      "DISCHARGE CONDITION :\n",
      "Stable\n",
      "TO DO / PLAN :\n",
      "f / u with PCP and Dr. Pump as scheduled , return to ED with worsening sob or increased cough or sputum production]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 259\n",
      "\t219\n",
      "\t3\n",
      "\t0\n",
      "\t3\n",
      "\t4\n",
      "\t2\n",
      "\t28\n",
      "could not split the string\n",
      "\n",
      "[Service :\n",
      "MEDICINE\n",
      "History of Present Illness :\n",
      "The patient is a 58 - year-old man with history of IDDM , PVD , status post toe amputations , diabetic neuropathy , and retinopathy recently admitted to McLean Hospital from 2017-01-13 , through 2017-01-18 , with a diagnosis of right heel diabetic ulcer with MSSA osteomyelitis of the calcaneus , MSSA bacteremia , acute interstitial nephritis secondary to oxacillin , and RLL pna .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 116\n",
      "\t116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not split the string\n",
      "\n",
      "[ASSOCIATED PROCEDURES OR OPERATIONS :\n",
      "POSTPARTUM DIAGNOSTIC PROCEDURES :\n",
      "None\n",
      "POSTPARTUM THERAPEUTIC PROCEDURES :\n",
      "None\n",
      "OTHER POSTPARTUM THERAPIES :\n",
      "Routine Post Partum Care\n",
      "HISTORY AND REASON FOR HOSPITALIZATION :\n",
      "Premature Rupture Of Membranes\n",
      "HOSPITAL COURSE ( include complications if any ) :\n",
      "This 27 year old Gravida 1 Para 0000 was admitted to the Life Valley Medical Center Obstetrical service on 10/31/2004 at 08:45 pm for the indication ( s ) :\n",
      "premature rupture of membranes .]\n",
      "\n",
      "\n",
      "Assuming this text is is a large paragraph and splitting\n",
      "LET'S KICK IT INTO OVERDRIVE\n",
      "original length: 103\n",
      "\t0\n",
      "\t5\n",
      "\t0\n",
      "\t6\n",
      "\t1\n",
      "\t6\n",
      "\t1\n",
      "\t8\n",
      "\t5\n",
      "\t7\n",
      "\t46\n",
      "\t2\n",
      "\t16\n",
      "********************************************************************************\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "TRAINNING_DATA_DIR = \"./corpus/i2b2/2012-07-15.original-annotation.release/\"\n",
    "TEST_DATA_DIR = \"./corpus/i2b2/ground_truth/merged_xml/\"\n",
    "SAVE_DIR = \"./corpus/i2b2/\"\n",
    "\n",
    "\n",
    "import transformers\n",
    "from transformers.tokenization_bert import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def file_name(file_dir):\n",
    "    L=[]\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1] == '.xml':\n",
    "                L.append(file)\n",
    "    return L\n",
    "\n",
    "\n",
    "\n",
    "def create_entry(tlink, text, f = ''):\n",
    "    id = f[:-4] +\"_\"+ str(tlink.attrib['id'] )\n",
    "    target = tlink.attrib['fromText'] + \" \" + tlink.attrib['toText']\n",
    "    label = tlink.attrib['type'].upper()\n",
    "    if label == '':\n",
    "        return \"\"\n",
    "    \n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    \n",
    "    #print(id + \"\\t\"+target + \"\\t\" + label)\n",
    "    return id + \"\\t\" + target + \"\\t\" + text + \"\\t\"+ label\n",
    "\n",
    "\n",
    "def data_process(inDIR, outFile):\n",
    "    fileList = file_name(inDIR)\n",
    "    lableType = set()\n",
    "    outFile = open(outFile, \"w\")\n",
    "    \n",
    "    fileList.sort()\n",
    "    \n",
    "    #fileList = fileList[:6]\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for f in fileList:\n",
    "        \n",
    "        #print(f, end=' ')\n",
    "        linkNO = 0\n",
    "        inFile = open(inDIR + f, \"r\")\n",
    "        xmlString = \"\"\n",
    "        for lines in inFile.readlines():\n",
    "            xmlString += lines.replace(\" & \", \" \").replace(\"&\", \" and \")\n",
    "        inFile.close()\n",
    "\n",
    "        parser = ET.XMLParser(encoding=\"utf-8\")\n",
    "        root = ET.fromstring(xmlString, parser=parser)\n",
    "        text = root.find(\"TEXT\").text         \n",
    "        tags = root.find(\"TAGS\")\n",
    "    \n",
    "        \n",
    "        text = text.split(\"\\n\")[5:]\n",
    "        text = \"\\n\".join(text)\n",
    "        \n",
    "        text = re.sub(r\"\\n\\d+\\. \",\"\\n* \",text)\n",
    "        text = re.sub(r\"\\n\\d+\\) \",\"\\n* \",text)\n",
    "        text = re.sub(r\"\\n# \",\"\\n* \",text)\n",
    "        text = re.sub(r\"\\n-(-*)\",\"\\n* \",text)\n",
    "        text = re.sub(r\"\\n\\* \",\"\\n· \",text)\n",
    "        \n",
    "        \n",
    "        sentences = custom_sentence_tokenizer(text, tokenizer, testing = False, verbose = True)\n",
    "        \n",
    "    \n",
    "        final = []\n",
    "        for tlink in tags.findall(\"TLINK\"):\n",
    "            \n",
    "                id = f[:-4] +\"_\"+ str(tlink.attrib['id'] )\n",
    "                to_text = tlink.attrib['fromText']\n",
    "                from_text = tlink.attrib['toText']\n",
    "                \n",
    "                for sentence in sentences:\n",
    "                    if to_text in sentence and from_text in sentence:\n",
    "                        final.append(create_entry(tlink, sentence, f))\n",
    "                        \n",
    "        final2 = [i + \"\\n\" for i in final if i != \"\"]\n",
    "        outFile.writelines(final2)\n",
    "\n",
    "        \n",
    "    outFile.close()\n",
    "    print(\"*\"*80)\n",
    "\n",
    "data_process( TRAINNING_DATA_DIR , SAVE_DIR + \"medical_lists_nltk_train.txt\")\n",
    "data_process( TEST_DATA_DIR , SAVE_DIR + \"medical_lists_nltk_test.txt\")\n",
    "print(\"Done\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
