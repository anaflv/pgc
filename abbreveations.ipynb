{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "********************************************************************************\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "\n",
    "TRAINNING_DATA_DIR = \"./corpus/i2b2/2012-07-15.original-annotation.release/\"\n",
    "TEST_DATA_DIR = \"./corpus/i2b2/ground_truth/merged_xml/\"\n",
    "SAVE_DIR = \"./corpus/i2b2/\"\n",
    "\n",
    "\n",
    "import transformers\n",
    "from transformers.tokenization_bert import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
    "\n",
    "\n",
    "\n",
    "def file_name(file_dir):\n",
    "    L=[]\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1] == '.xml':\n",
    "                L.append(file)\n",
    "    return L\n",
    "\n",
    "\n",
    "\n",
    "def create_entry(tlink, text, f = ''):\n",
    "    _id = f[:-4] +\"_\"+ str(tlink.attrib['id'] )\n",
    "    from_text = remove_abbreviations(tlink.attrib['fromText'])\n",
    "    to_text = remove_abbreviations(tlink.attrib['toText'])\n",
    "    \n",
    "    #Use pipe instead of just blank space\n",
    "    target = from_text + \"|\" + to_text\n",
    "    label = tlink.attrib['type'].upper()\n",
    "    if label == '':\n",
    "        return \"\"\n",
    "    \n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return _id + \"\\t\" + target + \"\\t\" + text + \"\\t\"+ label\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def remove_abbreviations(text):\n",
    "    \n",
    "    abrev = ['pt', 'ct', 'ekg', 'f', 'cath', 'lad', 'pcp', 'cad', 'abd', 'r', 'hr', 'neuro', 'pod', 'ra', 'bs', 'pa', 'rrr']\n",
    "\n",
    "    dic =  { \n",
    "        \"f\":   \"female\",\n",
    "        \"pt\":\t\"patient\",\n",
    "        \"ct\":\t\"x-ray computed tomography\",\n",
    "        \"ekg\":\t\"electrocardiogram\",\n",
    "        \"cath\":\t\"catheterization\",\n",
    "        \"lad\":\t\"anterior descending branch of left coronary artery\",\n",
    "        \"pcp\":\t\"primary care physicians\",\n",
    "        \"cad\":\t\"coronary artery disease\",\n",
    "        \"abd\":\t\"examination of abdomen\",\n",
    "        \"bp\":\t\"blood pressure finding\",\n",
    "        \"r\":\t\"right\",\n",
    "        \"hr\":\t\"finding of heart rate\",\n",
    "        \"neuro\":\t\"neurological exam\",\n",
    "        \"pod\":\t\"postoperative day\",\n",
    "        \"ra\":\t\"on room air\",\n",
    "        \"bs\":\t\"bowel sounds\",\n",
    "        \"pa\":\t\"postero-anterior\",\n",
    "        \"rrr\":\t\"cardiac rhythm and/or rate finding\"\n",
    "        }\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    for a in abrev:\n",
    "        \n",
    "        if re.search(r'\\b' + a + r'\\b', text):\n",
    "            text = re.sub(r'\\b' + a + r'\\b',dic.get(a), str(text))\n",
    "            #print(\"{} - {} - {}\".format(text, a, dic.get(a)))\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def data_process(inDIR, outFile):\n",
    "        \n",
    "    fileList = file_name(inDIR)\n",
    "    lableType = set()\n",
    "    outFile = open(outFile, \"w\")\n",
    "    \n",
    "    fileList.sort()\n",
    "    \n",
    "    \n",
    "    for f in fileList:\n",
    "        \n",
    "        linkNO = 0\n",
    "        inFile = open(inDIR + f, \"r\")\n",
    "        xmlString = \"\"\n",
    "        for lines in inFile.readlines():\n",
    "            xmlString += lines.replace(\" & \", \" \").replace(\"&\", \" and \")\n",
    "        inFile.close()\n",
    "\n",
    "        parser = ET.XMLParser(encoding=\"latin-1\")\n",
    "        root = ET.fromstring(xmlString, parser=parser)\n",
    "        text = root.find(\"TEXT\").text         \n",
    "        tags = root.find(\"TAGS\")\n",
    "    \n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        doc = nlp(text)\n",
    "\n",
    "        sentences = [str(i) for i in list(doc.sents)]\n",
    "        modified_text = []\n",
    "        \n",
    "        #For each sentence, replace the abbreviation w/ the corresponding term\n",
    "        for s in sentences:\n",
    "            _s = s.lower()\n",
    "            modified_text.append(remove_abbreviations(_s))\n",
    "            \n",
    "        text = \" \".join(modified_text)        \n",
    "                        \n",
    "        final = []\n",
    "        for tlink in tags.findall(\"TLINK\"):            \n",
    "            final.append(create_entry(tlink, text, f))\n",
    "                                        \n",
    "        final2 = [i + \"\\n\" for i in final if i != \"\"]   \n",
    "                \n",
    "        outFile.writelines(final2)\n",
    "        \n",
    "\n",
    "    outFile.close()\n",
    "    print(\"*\"*80)\n",
    "    \n",
    "\n",
    "data_process( TRAINNING_DATA_DIR , SAVE_DIR + \"abbreviations_train.txt\")\n",
    "data_process( TEST_DATA_DIR , SAVE_DIR + \"abbreviations_test.txt\")\n",
    "\n",
    "print(\"Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
